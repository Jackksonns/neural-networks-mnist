{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopfield Network and RBM Comparison Experiments\n",
    "\n",
    "This notebook compares the performance of Hopfield networks and Restricted Boltzmann Machines on the MNIST dataset, including comparisons of storage capacity, noise robustness, convergence speed, and feature learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.hopfield.network import HopfieldNetwork\n",
    "from src.hopfield.visualizer import HopfieldVisualizer\n",
    "from src.hopfield.experiments import HopfieldExperiments\n",
    "from src.boltzmann.rbm import RBM\n",
    "from src.boltzmann.sampler import RBMSampler\n",
    "from src.boltzmann.experiments import RBMExperiments\n",
    "from src.utils.data_loader import MNISTLoader\n",
    "from src.utils.preprocessing import binary_to_image\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "loader = MNISTLoader()\n",
    "\n",
    "# Load MNIST data\n",
    "train_data = loader.get_train_data(binary_values={0, 1})\n",
    "test_data = loader.get_test_data(binary_values={0, 1})\n",
    "\n",
    "# Get specific digit samples for Hopfield network\n",
    "digits_to_use = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "hopfield_samples = []\n",
    "hopfield_labels = []\n",
    "\n",
    "for digit in digits_to_use:\n",
    "    # Take 5 samples for each digit\n",
    "    for i in range(5):\n",
    "        sample, label = loader.get_specific_digit_sample(digit, binary_values={0, 1})\n",
    "        hopfield_samples.append(sample)\n",
    "        hopfield_labels.append(label)\n",
    "\n",
    "# Convert to tensors\n",
    "hopfield_samples = torch.stack(hopfield_samples)\n",
    "hopfield_labels = torch.tensor(hopfield_labels)\n",
    "\n",
    "# Create data loaders for RBM\n",
    "train_loader = data.DataLoader(train_data, batch_size=config.RBM_CONFIG['batch_size'], shuffle=True)\n",
    "test_loader = data.DataLoader(test_data, batch_size=config.RBM_CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "print(f\"Hopfield samples shape: {hopfield_samples.shape}\")\n",
    "print(f\"RBM training samples: {len(train_data)}\")\n",
    "print(f\"RBM test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hopfield Network Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Hopfield network\n",
    "n_neurons = hopfield_samples.shape[1]  # 784 (28*28)\n",
    "hopfield_net = HopfieldNetwork(n_neurons=n_neurons)\n",
    "\n",
    "# Train Hopfield network\n",
    "print(\"Training Hopfield network...\")\n",
    "hopfield_train_time = time.time()\n",
    "hopfield_net.train(hopfield_samples)\n",
    "hopfield_train_time = time.time() - hopfield_train_time\n",
    "print(f\"Hopfield training time: {hopfield_train_time:.2f} seconds\")\n",
    "\n",
    "# Create visualizer\n",
    "hopfield_viz = HopfieldVisualizer(hopfield_net)\n",
    "\n",
    "# Create experiment manager\n",
    "hopfield_exp = HopfieldExperiments(hopfield_net, hopfield_viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Hopfield network storage capacity\n",
    "print(\"Testing Hopfield network storage capacity...\")\n",
    "\n",
    "# Test different numbers of patterns\n",
    "pattern_counts = [5, 10, 20, 30, 40, 50]\n",
    "hopfield_accuracies = []\n",
    "hopfield_convergence_times = []\n",
    "\n",
    "for count in pattern_counts:\n",
    "    # Select specified number of patterns\n",
    "    patterns = hopfield_samples[:count]\n",
    "    \n",
    "    # Create new network\n",
    "    net = HopfieldNetwork(n_neurons=n_neurons)\n",
    "    \n",
    "    # Train network\n",
    "    net.train(patterns)\n",
    "    \n",
    "    # Test recovery ability\n",
    "    correct = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        # Add small amount of noise\n",
    "        noisy_pattern = pattern.clone()\n",
    "        noise_indices = torch.randperm(noisy_pattern.size(0))[:int(0.1 * noisy_pattern.size(0))]\n",
    "        noisy_pattern[noise_indices] = 1 - noisy_pattern[noise_indices]\n",
    "        \n",
    "        # Recover pattern\n",
    "        start_time = time.time()\n",
    "        recovered, converged = net.recover(noisy_pattern, max_iterations=100)\n",
    "        total_time += time.time() - start_time\n",
    "        \n",
    "        # Check if correctly recovered\n",
    "        if torch.allclose(recovered, pattern, atol=1e-5):\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / len(patterns)\n",
    "    avg_time = total_time / len(patterns)\n",
    "    \n",
    "    hopfield_accuracies.append(accuracy)\n",
    "    hopfield_convergence_times.append(avg_time)\n",
    "    \n",
    "    print(f\"Patterns: {count}, Accuracy: {accuracy:.4f}, Avg. Convergence Time: {avg_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RBM Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RBM\n",
    "rbm = RBM(\n",
    "    n_visible=config.RBM_CONFIG['n_visible'],\n",
    "    n_hidden=config.RBM_CONFIG['n_hidden'],\n",
    "    k=config.RBM_CONFIG['k'],\n",
    "    learning_rate=config.RBM_CONFIG['learning_rate'],\n",
    "    momentum=config.RBM_CONFIG['momentum'],\n",
    "    weight_decay=config.RBM_CONFIG['weight_decay'],\n",
    "    use_cuda=config.RBM_CONFIG['use_cuda']\n",
    ")\n",
    "\n",
    "# Train RBM\n",
    "print(\"Training RBM...\")\n",
    "rbm_train_time = time.time()\n",
    "rbm_errors = []\n",
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    batch_errors = []\n",
    "    \n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        # Flatten data and binarize\n",
    "        batch = data.view(data.size(0), -1)\n",
    "        batch = (batch > 0.5).float()  # Binarize\n",
    "        \n",
    "        if rbm.use_cuda:\n",
    "            batch = batch.cuda()\n",
    "        \n",
    "        # Train one batch\n",
    "        error = rbm.train_batch(batch)\n",
    "        batch_errors.append(error)\n",
    "    \n",
    "    # Calculate average error\n",
    "    avg_error = np.mean(batch_errors)\n",
    "    rbm_errors.append(avg_error)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Error: {avg_error:.6f}\")\n",
    "\n",
    "rbm_train_time = time.time() - rbm_train_time\n",
    "print(f\"RBM training time: {rbm_train_time:.2f} seconds\")\n",
    "\n",
    "# Create sampler\n",
    "rbm_sampler = RBMSampler(rbm)\n",
    "\n",
    "# Create experiment manager\n",
    "rbm_exp = RBMExperiments(rbm, rbm_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Storage Capacity Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare storage capacities\n",
    "print(\"Comparing storage capacities...\")\n",
    "\n",
    "# Hopfield network capacity test (already completed above)\n",
    "hopfield_capacity = pattern_counts[np.argmax(hopfield_accuracies)]\n",
    "print(f\"Hopfield network effective capacity: ~{hopfield_capacity} patterns\")\n",
    "\n",
    "# RBM capacity test\n",
    "rbm_pattern_counts = [50, 100, 200, 500, 1000, 2000, 5000]\n",
    "rbm_accuracies = []\n",
    "\n",
    "for count in rbm_pattern_counts:\n",
    "    # Create data loader\n",
    "    subset_data = data.Subset(train_data, range(count))\n",
    "    subset_loader = data.DataLoader(subset_data, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # Create new RBM\n",
    "    test_rbm = RBM(\n",
    "        n_visible=config.RBM_CONFIG['n_visible'],\n",
    "        n_hidden=config.RBM_CONFIG['n_hidden'],\n",
    "        k=config.RBM_CONFIG['k'],\n",
    "        learning_rate=config.RBM_CONFIG['learning_rate'],\n",
    "        momentum=config.RBM_CONFIG['momentum'],\n",
    "        weight_decay=config.RBM_CONFIG['weight_decay'],\n",
    "        use_cuda=config.RBM_CONFIG['use_cuda']\n",
    "    )\n",
    "    \n",
    "    # Train RBM\n",
    "    for epoch in range(10):  # Fewer training epochs to save time\n",
    "        for batch_idx, (data, _) in enumerate(subset_loader):\n",
    "            batch = data.view(data.size(0), -1)\n",
    "            batch = (batch > 0.5).float()\n",
    "            \n",
    "            if test_rbm.use_cuda:\n",
    "                batch = batch.cuda()\n",
    "            \n",
    "            test_rbm.train_batch(batch)\n",
    "    \n",
    "    # Test reconstruction ability\n",
    "    test_subset = data.Subset(test_data, range(100))  # Use 100 test samples\n",
    "    test_loader = data.DataLoader(test_subset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    total_error = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for data, _ in test_loader:\n",
    "        batch = data.view(data.size(0), -1)\n",
    "        batch = (batch > 0.5).float()\n",
    "        \n",
    "        if test_rbm.use_cuda:\n",
    "            batch = batch.cuda()\n",
    "        \n",
    "        # Calculate reconstruction error\n",
    "        reconstructed = test_rbm.reconstruct(batch)\n",
    "        error = torch.mean((batch - reconstructed) ** 2).item()\n",
    "        \n",
    "        total_error += error * batch.size(0)\n",
    "        total_samples += batch.size(0)\n",
    "    \n",
    "    avg_error = total_error / total_samples\n",
    "    accuracy = 1 - avg_error  # Convert error to accuracy\n",
    "    rbm_accuracies.append(accuracy)\n",
    "    \n",
    "    print(f\"Patterns: {count}, Reconstruction Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot storage capacity comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot Hopfield network results\n",
    "ax.plot(pattern_counts, hopfield_accuracies, 'b-o', label='Hopfield Network', linewidth=2)\n",
    "\n",
    "# Plot RBM results (using different x-axis)\n",
    "ax2 = ax.twiny()\n",
    "ax2.plot(rbm_pattern_counts, rbm_accuracies, 'r-s', label='RBM', linewidth=2)\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('Number of Patterns (Hopfield)', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Storage Capacity Comparison', fontsize=14)\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "ax2.set_xlabel('Number of Training Samples (RBM)', fontsize=12)\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Noise Robustness Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare noise robustness\n",
    "print(\"Comparing noise robustness...\")\n",
    "\n",
    "# Test different noise levels\n",
    "noise_levels = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
    "hopfield_noise_accuracies = []\n",
    "rbm_noise_accuracies = []\n",
    "\n",
    "# Select test samples\n",
    "test_samples = hopfield_samples[:10]  # Use first 10 samples\n",
    "\n",
    "for noise_level in noise_levels:\n",
    "    # Test Hopfield network\n",
    "    hopfield_correct = 0\n",
    "    \n",
    "    for sample in test_samples:\n",
    "        # Add noise\n",
    "        noisy_sample = sample.clone()\n",
    "        noise_indices = torch.randperm(noisy_sample.size(0))[:int(noise_level * noisy_sample.size(0))]\n",
    "        noisy_sample[noise_indices] = 1 - noisy_sample[noise_indices]\n",
    "        \n",
    "        # Recover pattern\n",
    "        recovered, converged = hopfield_net.recover(noisy_sample, max_iterations=100)\n",
    "        \n",
    "        # Check if correctly recovered\n",
    "        if torch.allclose(recovered, sample, atol=1e-5):\n",
    "            hopfield_correct += 1\n",
    "    \n",
    "    hopfield_accuracy = hopfield_correct / len(test_samples)\n",
    "    hopfield_noise_accuracies.append(hopfield_accuracy)\n",
    "    \n",
    "    # Test RBM\n",
    "    rbm_total_error = 0\n",
    "    \n",
    "    for sample in test_samples:\n",
    "        # Add noise\n",
    "        noisy_sample = sample.clone()\n",
    "        noise_indices = torch.randperm(noisy_sample.size(0))[:int(noise_level * noisy_sample.size(0))]\n",
    "        noisy_sample[noise_indices] = 1 - noisy_sample[noise_indices]\n",
    "        \n",
    "        if rbm.use_cuda:\n",
    "            noisy_sample = noisy_sample.cuda()\n",
    "        \n",
    "        # Reconstruct\n",
    "        reconstructed = rbm.reconstruct(noisy_sample.unsqueeze(0))\n",
    "        error = torch.mean((noisy_sample - reconstructed) ** 2).item()\n",
    "        rbm_total_error += error\n",
    "    \n",
    "    avg_error = rbm_total_error / len(test_samples)\n",
    "    rbm_accuracy = 1 - avg_error\n",
    "    rbm_noise_accuracies.append(rbm_accuracy)\n",
    "    \n",
    "    print(f\"Noise Level: {noise_level:.2f}, Hopfield Accuracy: {hopfield_accuracy:.4f}, RBM Accuracy: {rbm_accuracy:.4f}\")\n",
    "\n",
    "# Plot noise robustness comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(noise_levels, hopfield_noise_accuracies, 'b-o', label='Hopfield Network', linewidth=2)\n",
    "ax.plot(noise_levels, rbm_noise_accuracies, 'r-s', label='RBM', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Noise Level', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Noise Robustness Comparison', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Convergence Speed Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare convergence speeds\n",
    "print(\"Comparing convergence speeds...\")\n",
    "\n",
    "# Hopfield network convergence test\n",
    "hopfield_iterations = []\n",
    "hopfield_times = []\n",
    "\n",
    "for sample in test_samples[:5]:  # Use first 5 samples\n",
    "    # Add noise\n",
    "    noisy_sample = sample.clone()\n",
    "    noise_indices = torch.randperm(noisy_sample.size(0))[:int(0.1 * noisy_sample.size(0))]\n",
    "    noisy_sample[noise_indices] = 1 - noisy_sample[noise_indices]\n",
    "    \n",
    "    # Measure convergence time and iterations\n",
    "    start_time = time.time()\n",
    "    recovered, converged = hopfield_net.recover(noisy_sample, max_iterations=1000)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    hopfield_iterations.append(converged)\n",
    "    hopfield_times.append(end_time - start_time)\n",
    "\n",
    "# RBM reconstruction test\n",
    "rbm_times = []\n",
    "rbm_gibbs_steps = [10, 20, 50, 100, 200, 500]\n",
    "rbm_errors = []\n",
    "\n",
    "for steps in rbm_gibbs_steps:\n",
    "    total_error = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for sample in test_samples[:5]:\n",
    "        # Add noise\n",
    "        noisy_sample = sample.clone()\n",
    "        noise_indices = torch.randperm(noisy_sample.size(0))[:int(0.1 * noisy_sample.size(0))]\n",
    "        noisy_sample[noise_indices] = 1 - noisy_sample[noise_indices]\n",
    "        \n",
    "        if rbm.use_cuda:\n",
    "            noisy_sample = noisy_sample.cuda()\n",
    "        \n",
    "        # Measure reconstruction time and error\n",
    "        start_time = time.time()\n",
    "        reconstructed = rbm.reconstruct(noisy_sample.unsqueeze(0), n_gibbs_steps=steps)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        error = torch.mean((noisy_sample - reconstructed) ** 2).item()\n",
    "        \n",
    "        total_error += error\n",
    "        total_time += end_time - start_time\n",
    "    \n",
    "    avg_error = total_error / 5\n",
    "    avg_time = total_time / 5\n",
    "    \n",
    "    rbm_errors.append(avg_error)\n",
    "    rbm_times.append(avg_time)\n",
    "    \n",
    "    print(f\"Gibbs Steps: {steps}, Avg. Error: {avg_error:.6f}, Avg. Time: {avg_time:.4f}s\")\n",
    "\n",
    "print(f\"\\nHopfield Network:\")\n",
    "print(f\"Avg. Iterations: {np.mean(hopfield_iterations):.2f}\")\n",
    "print(f\"Avg. Time: {np.mean(hopfield_times):.4f}s\")\n",
    "\n",
    "# Plot convergence speed comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Hopfield network iteration count distribution\n",
    "ax1.hist(hopfield_iterations, bins=10, alpha=0.7, color='blue')\n",
    "ax1.set_xlabel('Iterations to Convergence', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.set_title('Hopfield Network Convergence', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# RBM reconstruction error vs Gibbs steps\n",
    "ax2.plot(rbm_gibbs_steps, rbm_errors, 'r-o', linewidth=2)\n",
    "ax2.set_xlabel('Gibbs Steps', fontsize=12)\n",
    "ax2.set_ylabel('Reconstruction Error', fontsize=12)\n",
    "ax2.set_title('RBM Reconstruction Error vs Gibbs Steps', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Learning Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature learning capabilities\n",
    "print(\"Comparing feature learning capabilities...\")\n",
    "\n",
    "# Hopfield network features (weight matrix)\n",
    "hopfield_weights = hopfield_net.weights.detach().numpy()\n",
    "\n",
    "# RBM features (weight matrix)\n",
    "rbm_weights = rbm.get_weights().detach().cpu().numpy()\n",
    "\n",
    "# Visualize weight patterns\n",
    "fig, axes = plt.subplots(2, 10, figsize=(20, 4))\n",
    "\n",
    "# Display Hopfield network weight patterns (select 10 neurons)\n",
    "hopfield_indices = np.random.choice(hopfield_weights.shape[0], 10, replace=False)\n",
    "for i, idx in enumerate(hopfield_indices):\n",
    "    weight_img = hopfield_weights[idx].reshape(28, 28)\n",
    "    axes[0, i].imshow(weight_img, cmap='seismic')\n",
    "    axes[0, i].set_title(f'Neuron {idx}', fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Display RBM weight patterns (select 10 hidden units)\n",
    "rbm_indices = np.random.choice(rbm_weights.shape[1], 10, replace=False)\n",
    "for i, idx in enumerate(rbm_indices):\n",
    "    weight_img = rbm_weights[:, idx].reshape(28, 28)\n",
    "    axes[1, i].imshow(weight_img, cmap='seismic')\n",
    "    axes[1, i].set_title(f'Hidden {idx}', fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "# Set titles\n",
    "axes[0, 0].set_ylabel('Hopfield Network', fontsize=12)\n",
    "axes[1, 0].set_ylabel('RBM', fontsize=12)\n",
    "\n",
    "fig.suptitle('Weight Patterns Comparison', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comprehensive Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance comparison table\n",
    "print(\"Creating comprehensive performance comparison...\")\n",
    "\n",
    "# Prepare data\n",
    "comparison_data = {\n",
    "    'Metric': ['Training Time (s)', 'Storage Capacity', 'Noise Robustness (10%)', \n",
    "               'Avg. Convergence Time (s)', 'Feature Learning'],\n",
    "    'Hopfield Network': [\n",
    "        f\"{hopfield_train_time:.2f}\",\n",
    "        f\"~{hopfield_capacity} patterns\",\n",
    "        f\"{hopfield_noise_accuracies[1]:.4f}\",\n",
    "        f\"{np.mean(hopfield_times):.4f}\",\n",
    "        \"Hebbian Learning\"\n",
    "    ],\n",
    "    'RBM': [\n",
    "        f\"{rbm_train_time:.2f}\",\n",
    "        \"Large (scales with data)\",\n",
    "        f\"{rbm_noise_accuracies[1]:.4f}\",\n",
    "        f\"{rbm_times[2]:.4f}\",\n",
    "        \"Contrastive Divergence\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "display(comparison_df)\n",
    "\n",
    "# Save comparison results\n",
    "comparison_df.to_csv('../results/comparison_results.csv', index=False)\n",
    "print(\"Comparison results saved to '../results/comparison_results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Recovery Example Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize recovery examples\n",
    "print(\"Visualizing recovery examples...\")\n",
    "\n",
    "# Select test samples\n",
    "test_samples = hopfield_samples[:5]\n",
    "noise_level = 0.15\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "\n",
    "for i, sample in enumerate(test_samples):\n",
    "    # Original image\n",
    "    original_img = binary_to_image(sample.numpy(), (28, 28))\n",
    "    axes[0, i].imshow(original_img, cmap='binary')\n",
    "    axes[0, i].set_title(f'Original {i}', fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Add noise\n",
    "    noisy_sample = sample.clone()\n",
    "    noise_indices = torch.randperm(noisy_sample.size(0))[:int(noise_level * noisy_sample.size(0))]\n",
    "    noisy_sample[noise_indices] = 1 - noisy_sample[noise_indices]\n",
    "    noisy_img = binary_to_image(noisy_sample.numpy(), (28, 28))\n",
    "    axes[1, i].imshow(noisy_img, cmap='binary')\n",
    "    axes[1, i].set_title(f'Noisy {i}', fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Hopfield network recovery\n",
    "    hopfield_recovered, _ = hopfield_net.recover(noisy_sample, max_iterations=100)\n",
    "    hopfield_img = binary_to_image(hopfield_recovered.numpy(), (28, 28))\n",
    "    axes[2, i].imshow(hopfield_img, cmap='binary')\n",
    "    axes[2, i].set_title(f'Hopfield {i}', fontsize=10)\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "# Set row titles\n",
    "axes[0, 0].set_ylabel('Original', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Noisy', fontsize=12)\n",
    "axes[2, 0].set_ylabel('Recovered', fontsize=12)\n",
    "\n",
    "fig.suptitle('Recovery Examples Comparison', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/recovery_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create RBM recovery examples\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "\n",
    "for i, sample in enumerate(test_samples):\n",
    "    # Original image\n",
    "    original_img = binary_to_image(sample.numpy(), (28, 28))\n",
    "    axes[0, i].imshow(original_img, cmap='binary')\n",
    "    axes[0, i].set_title(f'Original {i}', fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Add noise\n",
    "    noisy_sample = sample.clone()\n",
    "    noise_indices = torch.randperm(noisy_sample.size(0))[:int(noise_level * noisy_sample.size(0))]\n",
    "    noisy_sample[noise_indices] = 1 - noisy_sample[noise_indices]\n",
    "    noisy_img = binary_to_image(noisy_sample.numpy(), (28, 28))\n",
    "    axes[1, i].imshow(noisy_img, cmap='binary')\n",
    "    axes[1, i].set_title(f'Noisy {i}', fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # RBM recovery\n",
    "    if rbm.use_cuda:\n",
    "        noisy_sample_cuda = noisy_sample.cuda()\n",
    "    else:\n",
    "        noisy_sample_cuda = noisy_sample\n",
    "    \n",
    "    rbm_recovered = rbm.reconstruct(noisy_sample_cuda.unsqueeze(0), n_gibbs_steps=100)\n",
    "    rbm_img = binary_to_image(rbm_recovered.detach().cpu().numpy(), (28, 28))[0]\n",
    "    axes[2, i].imshow(rbm_img, cmap='binary')\n",
    "    axes[2, i].set_title(f'RBM {i}', fontsize=10)\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "# Set row titles\n",
    "axes[0, 0].set_ylabel('Original', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Noisy', fontsize=12)\n",
    "axes[2, 0].set_ylabel('Recovered', fontsize=12)\n",
    "\n",
    "fig.suptitle('RBM Recovery Examples', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/rbm_recovery_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook compares the performance of Hopfield networks and Restricted Boltzmann Machines on the MNIST dataset, including:\n",
    "\n",
    "1. **Storage Capacity**: Hopfield networks have limited storage capacity, while RBMs can handle large amounts of data\n",
    "2. **Noise Robustness**: Both models have some noise robustness, but with different performance\n",
    "3. **Convergence Speed**: Hopfield networks converge faster, while RBMs require more Gibbs sampling steps\n",
    "4. **Feature Learning**: Hopfield networks use Hebbian learning, RBMs use contrastive divergence\n",
    "5. **Training Time**: RBMs typically require longer training times\n",
    "\n",
    "These comparisons help us understand the advantages and disadvantages of both models and their suitable application scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}